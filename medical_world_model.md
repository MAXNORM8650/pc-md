# Research Papers: medical world models

Updated: 2025-12-30 13:57
Total: 489 papers

---

## 1. Medical World Model

**Authors:** Yijun Yang, Zhao-Yang Wang, Qiuping Liu, Shuwen Sun, Kang Wang

**Year:** 2025 | **Venue:** ICCV 2025 | **Citations:** N/A | **Score:** 0.699

[PDF](https://openaccess.thecvf.com/content/ICCV2025/papers/Yang_Medical_World_Model_ICCV_2025_paper.pdf) | > Providing effective treatment and making informed decisions are essential goals of modern medicine and clinical care.We are interested in simulating disease dynamics for clinical decision-making, leveraging recent advances in large generative models.To this end, we introduce the Medical World Model (MeWM), the first world model in medicine that predicts future disease states based on clinical deci...

---

## 2. CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning

**Authors:** Yang Yue, Yulin Wang, Chenxin Tao, Pan Liu, Shiji Song

**Year:** 2025 | **Venue:** CVPR 2025 | **Citations:** N/A | **Score:** 0.696

[PDF](https://openaccess.thecvf.com/content/CVPR2025/papers/Yue_CheXWorld_Exploring_Image_World_Modeling_for_Radiograph_Representation_Learning_CVPR_2025_paper.pdf) | > Humans can develop internal world models that encode common sense knowledge, telling them how the world works and predicting the consequences of their actions. This concept has emerged as a promising direction for establishing general-purpose machine-learning models in recent preliminary works, e.g., for visual representation learning. In this paper, we present CheXWorld, the first effort towards ...

---

## 3. ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics in the Real World

**Authors:** Weixiang Yan, Haitian Liu, Tengxiao Wu, Qian Chen, Wen Wang

**Year:** 2025 | **Venue:** NIPS 2025 | **Citations:** N/A | **Score:** 0.651

> Large language models (LLMs) have achieved significant performance progress in various natural language processing applications. However, LLMs still struggle to meet the strict requirements for accuracy and reliability in the medical field and face many challenges in clinical applications. Existing clinical diagnostic evaluation benchmarks for evaluating medical agents powered by LLMs have severe ...

---

## 4. Medical Spoken Named Entity Recognition

**Authors:** Khai Le-Duc, David Thulke, Hung-Phong Tran, Long Vo-Dang, Khai-Nguyen Nguyen

**Year:** 2025 | **Venue:** NAACL 2025 | **Citations:** N/A | **Score:** 0.621

[PDF](https://aclanthology.org/2025.naacl-industry.59.pdf) | > Spoken Named Entity Recognition (NER) aims to extract named entities from speech and categorise them into types like person, location, organization, etc. In this work, we present *VietMed-NER* - the first spoken NER dataset in the medical domain. To our knowledge, our Vietnamese real-world dataset is the largest spoken NER dataset in the world regarding the number of entity types, featuring 18 dis...

---

## 5. Vid2World: Crafting Video Diffusion Models to Interactive World Models

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.608

> World models, which predict future transitions from past observation and action sequences, have shown great promise for improving data efficiency in sequential decision-making. However, existing world models often require extensive domain-specific training and still produce low-fidelity, coarse predictions, limiting their usefulness in complex environments. In contrast, video diffusion models trai...

---

## 6. Diffusion World Models

**Authors:** Eloi Alonso, Adam Jelley, Anssi Kanervisto, Tim Pearce

**Year:** 2024 | **Venue:** ICLR 2024 | **Citations:** N/A | **Score:** 0.599

> World models constitute a powerful and versatile tool for decision-making. Through their ability to predict future states of the world, they can replace environments for safe and fast simulation, and/or be leveraged for search at decision time. Advances in generative modeling have led to the development of new world models, that operate in visual environments with challenging dynamics. However, re...

---

## 7. Making Large Language Models into World Models with Precondition and Effect Knowledge

**Authors:** Kaige Xie, Ian Yang, John Gunerli, Mark Riedl

**Year:** 2025 | **Venue:** COLING 2025 | **Citations:** N/A | **Score:** 0.598

[PDF](https://aclanthology.org/2025.coling-main.503.pdf) | > World models, which encapsulate the dynamics of how actions affect environments, are foundational to the functioning of intelligent agents. In this work, we explore the potential of Large Language Models (LLMs) to operate as world models. Although LLMs are not inherently designed to model real-world dynamics, we show that they can be induced to perform two critical world model functions: determini...

---

## 8. RLVR-World: Training World Models with Reinforcement Learning

**Authors:** Jialong Wu, Shaofeng Yin, Ningya Feng, Mingsheng Long

**Year:** 2025 | **Venue:** NIPS 2025 | **Citations:** N/A | **Score:** 0.598

> World models predict state transitions in response to actions and are increasingly developed across diverse modalities. However, standard training objectives such as maximum likelihood estimation (MLE) often misalign with task-specific goals of world models, i.e., transition prediction metrics like accuracy or perceptual quality. In this paper, we present RLVR-World, a unified framework that lever...

---

## 9. MedCCO: Unleashing Open-Ended Reasoning in Medical Multi-modal Language Models via Curriculum Reinforcement Learning

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.585

> Recent advances in reinforcement learning with verifiable, rule-based rewards have greatly enhanced the reasoning capabilities and out-of-distribution generalization of VLMs/LLMs, obviating the need for manually crafted reasoning chains. Despite these promising developments in the general domain, their translation to medical imaging remains limited. Besides, current reinforcement fine-tuning (RFT)...

---

## 10. Benchmarking LLMs on Authentic Cases from Medical Journals

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.583

> In recent years, large language models (LLMs) have demonstrated remarkable capabilities in the medical domain. However, existing medical benchmarks suffer from performance saturation and are predominantly derived from medical exam questions, which fail to adequately capture the complexity of real-world clinical scenarios. To bridge this gap, we introduce ClinBench, a challenging benchmark based on...

---

## 11. When Case Gets Rare: A Retrieval Benchmark for Off-Guideline Medical Question Answering

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.582

> Across medical specialties, clinical practice is anchored in evidence-based guidelines that codify best studied diagnostic and treatment pathways. These pathways work well for the majority of patients but routinely fall short for the long tail of real-world care not covered by guidelines. Most medical large language models (LLMs), however, are trained to encode common, guideline-focused medical kn...

---

## 12. MediConfusion: Can you trust your AI radiologist? Probing the reliability of multimodal medical foundation models

**Authors:** Mohammad Shahab Sepehri, Zalan Fabian, Maryam Soltanolkotabi, Mahdi Soltanolkotabi

**Year:** 2025 | **Venue:** ICLR 2025 | **Citations:** N/A | **Score:** 0.580

[PDF](https://openreview.net/pdf?id=H9UnNgdq0g) | > Multimodal Large Language Models (MLLMs) have tremendous potential to improve the accuracy, availability, and cost-effectiveness of healthcare by providing automated solutions or serving as aids to medical professionals. Despite promising first steps in developing medical MLLMs in the past few years, their capabilities and limitations are not well understood. Recently, many benchmark datasets have...

---

## 13. KAMEL: Knowledge Aware Medical Entity Linkage to Automate Health Insurance Claims Processing

**Authors:** Sheng Jie Lui, Cheng Xiang, Shonali Krishnaswamy

**Year:** 2024 | **Venue:** AAAI 2024 | **Citations:** N/A | **Score:** 0.565

[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/30314/32328) | > Automating the processing of health insurance claims to achieve "Straight-Through Processing" is one of the holy grails that all insurance companies aim to achieve. One of the major impediments to this automation is the difficulty in establishing the relationship between the underwriting exclusions that a policy has and the incoming claim's diagnosis information. Typically, policy underwriting exc...

---

## 14. Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?

**Authors:** Daniel P Jeong, Saurabh Garg, Zachary Chase Lipton, Michael Oberst

**Year:** 2024 | **Venue:** EMNLP 2024 | **Citations:** N/A | **Score:** 0.564

[PDF](https://aclanthology.org/2024.emnlp-main.677.pdf) | > Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical l...

---

## 15. Context and Diversity Matter: The Emergence of In-Context Learning in World Models

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.564

> The capability of predicting environmental dynamics underpins both biological neural systems and general embodied AI in adapting to their surroundings. Yet prevailing approaches rest on static world models that falter when confronted with novel or rare configurations. We investigate in-context learning (ICL) of world models, shifting attention from zero-shot performance to the growth and asymptoti...

---

## 16. OntoFAR: Hierarchical Multi-Ontology Fusion Better Augments EHR Representation

**Authors:** Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Dongjie Wang, Zijun Yao

**Year:** 2025 | **Venue:** ICLR 2025 | **Citations:** N/A | **Score:** 0.564

> Medical ontology graphs, which typically organize and relate comprehensive medical concepts in a hierarchical structure, are able to map a rich set of external knowledge onto the specific medical codes observed in electronic health records (EHRs). Through the connectivity in ontologies, healthcare predictive models can utilize the ancestor, descendant, or sibling information to add supplementary c...

---

## 17. MedResearcher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.562

> Recent advances in Large Language Model (LLM)-based agents have enabled strong performance in deep research tasks, yet they remain limited in the medical domain. Leading proprietary systems achieve only modest results on complex medical benchmarks, revealing two critical limitations: 
(1) insufficient dense medical knowledge for clinical reasoning, and (2) a lack of specialized retrieval mechanism...

---

## 18. InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.558

> Multimodal large language models (MLLMs) have shown remarkable potential in various domains, yet their application in the medical field is hindered by several challenges. General-purpose MLLMs often lack the specialized knowledge required for medical tasks, leading to uncertain or hallucinatory responses. Knowledge distillation from advanced models struggles to capture domain-specific expertise in...

---

## 19. Elicit and Enhance: Advancing Multimodal Reasoning in Medical Scenarios

**Authors:** Zhongzhen Huang, Linjie Mu, Xiangyu Zhao, Yakun Zhu, Xiaofan Zhang

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.557

> Effective clinical decision-making depends on iterative, multimodal reasoning across diverse sources of evidence. The recent emergence of multimodal reasoning models has significantly transformed the landscape of solving complex tasks. Although such models have achieved notable success in mathematics and science, their application to medical domains remains underexplored. In this work, we propose ...

---

## 20. CliMedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large Language Models in Clinical Scenarios

**Authors:** Zetian Ouyang, Yishuai Qiu, Linlin Wang, Gerard De Melo, Ya Zhang

**Year:** 2024 | **Venue:** EMNLP 2024 | **Citations:** N/A | **Score:** 0.556

[PDF](https://aclanthology.org/2024.emnlp-main.480.pdf) | > With the proliferation of Large Language Models (LLMs) in diverse domains, there is a particular need for unified evaluation standards in clinical medical scenarios, where models need to be examined very thoroughly. We present CliMedBench, a comprehensive benchmark with 14 expert-guided core clinical scenarios specifically designed to assess the medical ability of LLMs across 7 pivot dimensions. I...

---

## 21. UniMedVL: Unifying Medical Multimodal Understanding and Generation through Observation-Knowledge-Analysis

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.555

> Clinical diagnosis demands models that can process multimodal medical inputs (images, patient histories, lab results) and generate diverse outputs including both textual reports and visual content (annotations, segmentation masks, and images). Despite this need, existing medical AI systems disrupt this unified process: medical image understanding models interpret images but cannot generate visual ...

---

## 22. Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment

**Authors:** Yaling Shen, Zhixiong Zhuang, Kun Yuan, Maria-Irina Nicolae, Nassir Navab

**Year:** 2025 | **Venue:** AAAI 2025 | **Citations:** N/A | **Score:** 0.550

[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/32734/34889) | > Medical multimodal large language models (MLLMs) are becoming an instrumental part of healthcare systems, assisting medical personnel with decision making and results analysis. Models for radiology report generation are able to interpret medical imagery, thus reducing the workload of radiologists. As medical data is scarce and protected by privacy regulations, medical MLLMs represent valuable inte...

---

## 23. MedEthicEval: Evaluating Large Language Models Based on Chinese Medical Ethics

**Authors:** Haoan Jin, Jiacheng Shi, Hanhui Xu, Kenny Q. Zhu, Mengyue Wu

**Year:** 2025 | **Venue:** NAACL 2025 | **Citations:** N/A | **Score:** 0.550

[PDF](https://aclanthology.org/2025.naacl-industry.34.pdf) | > Large language models (LLMs) demonstrate significant potential in advancing medical applications, yet their capabilities in addressing medical ethics challenges remain underexplored. This paper introduces MedEthicEval, a novel benchmark designed to systematically evaluate LLMs in the domain of medical ethics. Our framework encompasses two key components: knowledge, assessing the models’ grasp of m...

---

## 24. Learning World Models for Interactive Video Generation

**Authors:** Taiye Chen, Xun Hu, Zihan Ding, Chi Jin

**Year:** 2025 | **Venue:** NIPS 2025 | **Citations:** N/A | **Score:** 0.548

> Foundational world models must be both interactive and preserve spatialtemporal coherence to enable effective future planning with different action choices. However, present models for long video generation have limited inherent world modeling capabilities due to two main challenges: compounding errors and insufficient memory mechanisms. 
We enhance image-to-video models with interactive capabilit...

---

## 25. Small Models are LLM Knowledge Triggers for Medical Tabular Prediction

**Authors:** Jiahuan Yan, Jintai Chen, Chaowen Hu, Bo Zheng, Yaojun Hu

**Year:** 2025 | **Venue:** ICLR 2025 | **Citations:** N/A | **Score:** 0.548

[PDF](https://openreview.net/pdf?id=WoPovNkM5h) | > Recent development in large language models (LLMs) has demonstrated impressive domain proficiency on unstructured textual or multi-modal tasks. However, despite with intrinsic world knowledge, their application on structured tabular data prediction still lags behind, primarily due to the numerical insensitivity and modality discrepancy that brings a gap between LLM reasoning and statistical tabula...

---

## 26. Multi-modal Medical Diagnosis via Large-small Model Collaboration

**Authors:** Wanyi Chen, Zihua Zhao, Jiangchao Yao, Ya Zhang, Jiajun Bu

**Year:** 2025 | **Venue:** CVPR 2025 | **Citations:** N/A | **Score:** 0.548

[PDF](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Multi-modal_Medical_Diagnosis_via_Large-small_Model_Collaboration_CVPR_2025_paper.pdf) | > Recent advances in medical AI have shown a clear trend towards large models in healthcare. However, developing large models for multi-modal medical diagnosis remains challenging due to a lack of sufficient modal-complete medical data. Most existing multi-modal diagnostic models are relatively small and struggle with limited feature extraction capabilities. To bridge this gap, we propose **AdaCoMed...

---

## 27. Learning Knowledge Graph-based World Models of Textual Environments

**Authors:** Prithviraj Ammanabrolu, Mark Riedl

**Year:** 2021 | **Venue:** NIPS 2021 | **Citations:** N/A | **Score:** 0.548

[PDF](https://openreview.net/pdf?id=o24k_XfIe6_) | > World models improve a learning agent's ability to efficiently operate in interactive and situated environments. This work focuses on the task of building world models of text-based game environments. Text-based games, or interactive narratives, are reinforcement learning environments in which agents perceive and interact with the world using textual natural language. These environments contain lo...

---

## 28. Interpretable Bilingual Multimodal Large Language Model for Diverse Biomedical Tasks

**Authors:** Lehan Wang, Haonan Wang, Honglong Yang, Jiaji Mao, Zehong Yang

**Year:** 2025 | **Venue:** ICLR 2025 | **Citations:** N/A | **Score:** 0.547

[PDF](https://openreview.net/pdf?id=YuHQTo6G9S) | > Several medical Multimodal Large Languange Models (MLLMs) have been developed to address tasks involving visual images with textual instructions across various medical modalities, achieving impressive results. 
Most current medical generalist models are region-agnostic, treating the entire image as a holistic representation. However, they struggle to identify which specific regions they are focusi...

---

## 29. M3D: Advancing 3D Medical Image Analysis with Multi-Modal Large Language Models

**Authors:** Fan BAI, Yuxin Du, Tiejun Huang, Max q.-h. Meng, Bo Zhao

**Year:** 2025 | **Venue:** ICLR 2025 | **Citations:** N/A | **Score:** 0.547

> Medical image analysis is essential to numerous practicals of clinical diagnosis and treatment. However, due to the data scarcity and expensive training cost, previous research has largely focused on 2D medical image analysis, leaving 3D medical images under-explored, despite their important spatial information. This paper aims to advance 3D medical image analysis by leveraging multi-modal large l...

---

## 30. Medical Decision Tree-Enhanced LLMs for Interpretable Reasoning

**Authors:** Ruoyu Liu, Xiaofan Zhang, Shaoting Zhang

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.547

> Large Language Models have made significant strides in medical reasoning. However, challenges remain due to their limited medical knowledge and the risk of hallucinations. While RAG methods can mitigate these issues by retrieving relevant medical information, they typically supply verbose text fragments, which challenges the model's comprehension. Inspired by the widespread use and inherent interp...

---

## 31. MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making

**Authors:** Yubin Kim, Chanwoo Park, Hyewon Jeong, Yik Siu Chan, Xuhai Xu

**Year:** 2024 | **Venue:** NIPS 2024 | **Citations:** N/A | **Score:** 0.546

[PDF](https://openreview.net/pdf?id=EKdk4vxKO4) | > Foundation models are becoming valuable tools in medicine. Yet despite their promise, the best way to leverage Large Language Models (LLMs) in complex medical tasks remains an open question. We introduce a novel multi-agent framework, named **M**edical **D**ecision-making **Agents** (**MDAgents**) that helps to address this gap by automatically assigning a collaboration structure to a team of LLMs...

---

## 32. Towards All-in-One Medical Image Re-Identification

**Authors:** Yuan Tian, Kaiyuan Ji, Rongzhao Zhang, Yankai Jiang, Chunyi Li

**Year:** 2025 | **Venue:** CVPR 2025 | **Citations:** N/A | **Score:** 0.545

[PDF](https://openaccess.thecvf.com/content/CVPR2025/papers/Tian_Towards_All-in-One_Medical_Image_Re-Identification_CVPR_2025_paper.pdf) | > Medical image re-identification (MedReID) is under-explored so far, despite its critical applications in personalized healthcare and privacy protection.In this paper, we introduce a thorough benchmark and a unified model for this problem.First, to handle various medical modalities, we propose a novel Continuous Modality-based Parameter Adapter (ComPA). ComPA condenses medical content into a contin...

---

## 33. VILA-M3: Enhancing Vision-Language Models with Medical Expert Knowledge

**Authors:** Vishwesh Nath, Wenqi Li, Dong Yang, Andriy Myronenko, Mingxin Zheng

**Year:** 2025 | **Venue:** CVPR 2025 | **Citations:** N/A | **Score:** 0.545

[PDF](https://openaccess.thecvf.com/content/CVPR2025/papers/Nath_VILA-M3_Enhancing_Vision-Language_Models_with_Medical_Expert_Knowledge_CVPR_2025_paper.pdf) | > Generalist vision language models (VLMs) have made significant strides in computer vision, but they fall short in specialized fields like healthcare, where expert knowledge is essential. Current large multimodal models like Gemini and GPT-4o are insufficient for medical tasks due to their reliance on memorized internet knowledge rather than the nuanced expertise required in healthcare. Meanwhile, ...

---

## 34. Signature-Guided Adversarial Attacks On Healthcare LLMs: Exposing PII Leakage In RAG Systems

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.545

> The adoption of Large Language Models (LLMs) is accelerating across the healthcare domain. Medical assistants are increasingly used to implement and deploy medical databases and questioning models. Retrieval Augmented Generation (RAG) has become an alternative way to introduce LLMs to specific data, such as a medical specialty, by selecting relevant context to improve answer quality. However, stor...

---

## 35. MedSafetyBench: Evaluating and Improving the Medical Safety of Large Language Models

**Authors:** Tessa Han, Aounon Kumar, Chirag Agarwal, Himabindu Lakkaraju

**Year:** 2024 | **Venue:** NIPS 2024 | **Citations:** N/A | **Score:** 0.545

[PDF](https://openreview.net/pdf?id=cFyagd2Yh4) | > As large language models (LLMs) develop increasingly sophisticated capabilities and find applications in medical settings, it becomes important to assess their medical safety due to their far-reaching implications for personal and public health, patient safety, and human rights. However, there is little to no understanding of the notion of medical safety in the context of LLMs, let alone how to ev...

---

## 36. Interactive Evaluation for Medical LLMs via Task-oriented Dialogue System

**Authors:** Ruoyu Liu, Kui Xue, Xiaofan Zhang, Shaoting Zhang

**Year:** 2025 | **Venue:** COLING 2025 | **Citations:** N/A | **Score:** 0.544

[PDF](https://aclanthology.org/2025.coling-main.325.pdf) | > This study focuses on evaluating proactive communication and diagnostic capabilities of medical Large Language Models (LLMs), which directly impact their effectiveness in patient consultations. In typical medical scenarios, doctors often ask a set of questions to gain a comprehensive understanding of patients’ conditions. We argue that single-turn question-answering tasks such as MultiMedQA are in...

---

## 37. FineMedLM-o1: Enhancing Medical Knowledge Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training

**Authors:** hongzhou yu, Tianhao Cheng, Yingwen Wang, Wen He, Qing Wang

**Year:** 2025 | **Venue:** COLM 2025 | **Citations:** N/A | **Score:** 0.544

> Recent advancements in large language models (LLMs) have shown promise in medical applications such as disease diagnosis and treatment planning. However, most existing medical LLMs struggle with the deep reasoning required for complex medical problems, such as differential diagnosis and medication recommendations. We propose FineMedLM-o1, which leverages high-quality medical synthetic data and lon...

---

## 38. MultiMSD: A Corpus for Multilingual Medical Text Simplification from Online Medical References

**Authors:** Koki Horiguchi, Tomoyuki Kajiwara, Takashi Ninomiya, Shoko Wakamiya, Eiji Aramaki

**Year:** 2025 | **Venue:** ACL 2025 | **Citations:** N/A | **Score:** 0.543

[PDF](https://aclanthology.org/2025.findings-acl.481.pdf) | > We release a parallel corpus for medical text simplification, which paraphrases medical terms into expressions easily understood by patients. Medical texts written by medical practitioners contain a lot of technical terms, and patients who are non-experts are often unable to use the information effectively. Therefore, there is a strong social demand for medical text simplification that paraphrases...

---

## 39. Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback

**Authors:** Yucheng Zhou, Lingran Song, Jianbing Shen

**Year:** 2025 | **Venue:** ACL 2025 | **Citations:** N/A | **Score:** 0.543

[PDF](https://aclanthology.org/2025.acl-long.636.pdf) | > Existing Medical Large Vision-Language Models (Med-LVLMs), encapsulating extensive medical knowledge, demonstrate excellent capabilities in understanding medical images. However, there remain challenges in visual localization in medical images, which is crucial for abnormality detection and interpretation. To address these issues, we propose a novel UMed-LVLM designed to unveil medical abnormaliti...

---

## 40. Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale

**Authors:** Junying Chen, Chi Gui, Ruyi Ouyang, Anningzhe Gao, Shunian Chen

**Year:** 2024 | **Venue:** EMNLP 2024 | **Citations:** N/A | **Score:** 0.541

[PDF](https://aclanthology.org/2024.emnlp-main.418.pdf) | > The rapid development of multimodal large language models (MLLMs), such as GPT-4V, has led to significant advancements. However, these models still face challenges in medical multimodal capabilities due to limitations in the quantity and quality of medical vision-text data, stemming from data privacy concerns and high annotation costs. While pioneering approaches utilize PubMed’s large-scale, de-i...

---

## 41. Stand on Two Shoulders: Dynamically Merging Tokens from General and Medical Experts

**Authors:** Shentong Mo, Xufang Luo, Zilong Wang, Dongsheng Li

**Year:** 2025 | **Venue:** ICLR 2025 | **Citations:** N/A | **Score:** 0.540

> In the realm of medical image analysis, the transferability of pre-trained Vision Transformers (ViTs) to specialized medical tasks remains a significant challenge. Previous approaches focus on adapting a single model, by introducing specialized learnable layers to the pre-trained model. However, a single model optimized for general tasks underperforms in domain-specific applications, while one med...

---

## 42. How Do Medical MLLMs Fail? A Study on Visual Grounding in Medical Images

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.540

> Generalist multimodal large language models (MLLMs) have achieved impressive performance across a wide range of vision-language tasks. However, their performance on medical tasks—particularly in zero-shot settings where generalization is critical—remains suboptimal. A key research gap is the limited understanding of why medical MLLMs underperform in medical image interpretation.
**In this work**, ...

---

## 43. MEDMKG: Benchmarking Medical Knowledge Exploitation with Multimodal Knowledge Graph

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.539

> Medical deep learning models depend heavily on domain-specific knowledge to perform well on knowledge-intensive clinical tasks. Prior work has primarily leveraged unimodal knowledge graphs, such as the Unified Medical Language System (UMLS), to enhance model performance. However, integrating multimodal medical knowledge graphs remains largely underexplored, mainly due to the lack of resources link...

---

## 44. To Err Is Human, How about Medical Large Language Models? Comparing Pre-trained Language Models for Medical Assessment Errors and Reliability

**Authors:** Wen-wai Yim, Yujuan Fu, Asma Ben Abacha, Meliha Yetisgen

**Year:** 2024 | **Venue:** COLING 2024 | **Citations:** N/A | **Score:** 0.538

[PDF](https://aclanthology.org/2024.lrec-main.1409.pdf) | > Unpredictability, especially unpredictability with unknown error characteristics, is a highly undesirable trait, particularly in medical patient care applications. Although large pre-trained language models (LLM) have been applied to a variety of unseen tasks with highly competitive and successful results, their sensitivity to language inputs and resulting performance variability is not well-studi...

---

## 45. EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models

**Authors:** 

**Year:** 2026 | **Venue:** ICLR 2026 | **Citations:** N/A | **Score:** 0.537

> Recent benchmarks for medical Large Vision-Language Models (LVLMs) primarily focus on task-specific performance metrics, such as accuracy in visual question answering. However, focusing exclusively on leaderboard accuracy risks neglecting critical issues related to model reliability and safety in practical diagnostic scenarios. One significant yet underexplored issue is sycophancy — the propensity...

---

## 46. Towards Medical Complex Reasoning with LLMs through Medical Verifiable Problems

**Authors:** Junying Chen, Zhenyang Cai, Ke Ji, Xidong Wang, Wanlong Liu

**Year:** 2025 | **Venue:** ACL 2025 | **Citations:** N/A | **Score:** 0.537

[PDF](https://aclanthology.org/2025.findings-acl.751.pdf) | > The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning to improve LLM. Yet, most research in reasoning has focused on mathematical tasks, leaving domains like medicine underexplored. The medical domain, though distinct from mathematics, also demands robust reasoning to provide reliable answers, given the high standards of healthcare. However, verifying medical reasoning is c...

---

## 47. Stress-Testing of Multimodal Models in Medical Image-Based Report Generation

**Authors:** Flávia Carvalhido, Henrique Lopes Cardoso, Vítor Cerqueira

**Year:** 2025 | **Venue:** AAAI 2025 | **Citations:** N/A | **Score:** 0.536

[PDF](https://ojs.aaai.org/index.php/AAAI/article/view/35203/37358) | > Multimodal models, namely vision-language models, present unique possibilities through the seamless integration of different information mediums for data generation. These models mostly act as a black-box, making them lack transparency and explicability. Reliable results require accountable and trustworthy Artificial Intelligence (AI), namely when in use for critical tasks, such as the automatic g...

---

## 48. Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation

**Authors:** Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu

**Year:** 2025 | **Venue:** ACL 2025 | **Citations:** N/A | **Score:** 0.536

[PDF](https://aclanthology.org/2025.acl-long.1381.pdf) | > We introduce MedGraphRAG, a novel graph-based Retrieval-Augmented Generation (RAG) framework designed to enhance LLMs in generating evidence-based medical responses, improving safety and reliability with private medical data. We introduce Triple Graph Construction and U-Retrieval to enhance GraphRAG, enabling holistic insights and evidence-based response generation for medical applications. Specif...

---

## 49. Can We Trust AI Doctors? A Survey of Medical Hallucination in Large Language and Large Vision-Language Models

**Authors:** Zhihong Zhu, Yunyan Zhang, Xianwei Zhuang, Fan Zhang, Zhongwei Wan

**Year:** 2025 | **Venue:** ACL 2025 | **Citations:** N/A | **Score:** 0.536

[PDF](https://aclanthology.org/2025.findings-acl.350.pdf) | > Hallucination has emerged as a critical challenge for large language models (LLMs) and large vision-language models (LVLMs), particularly in high-stakes medical applications. Despite its significance, dedicated research on medical hallucination remains unexplored. In this survey, we first provide a unified perspective on medical hallucination for both LLMs and LVLMs, and delve into its causes. Sub...

---

## 50. Efficiency in Focus: LayerNorm as a Catalyst for Fine-tuning Medical Visual Language Models

**Authors:** Jiawei Chen, Dingkang Yang, Yue Jiang, Mingcheng Li, Jinjie Wei

**Year:** 2024 | **Venue:** ACMMM 2024 | **Citations:** N/A | **Score:** 0.535

> ...

---

